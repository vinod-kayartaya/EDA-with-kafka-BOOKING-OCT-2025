# Monitoring Kafka Applications in Spring Boot Using Micrometer, Prometheus, and Grafana

**By Vinod Kumar Kayartaya**
_Software Developer & Trainer_

## Overview

Monitoring is an essential part of building robust event-driven systems.
When working with Kafka-based applications (producers, consumers, and stream processors), visibility into message flow, performance, and lag is critical.

This tutorial demonstrates how to instrument a Spring Boot Kafka application using Micrometer and Prometheus, visualize the metrics in Grafana, and understand key Kafka metrics that help assess system health.

## What You’ll Learn

By the end of this post, you’ll be able to:

- Add Micrometer and Prometheus support to your Spring Boot Kafka application
- Expose internal Kafka client metrics (producer and consumer)
- Configure Prometheus to scrape metrics
- Visualize them in Grafana dashboards
- Interpret important Kafka metrics for performance tuning

## Prerequisites

- A working Spring Boot application using Kafka producer and consumer
- Docker Compose setup running:

  - Zookeeper
  - Kafka
  - Prometheus
  - Grafana

- Basic familiarity with Spring Boot Actuator

## Add Micrometer and Actuator Dependencies

Add the following dependencies to your `pom.xml`:

```xml
<!-- Spring Boot Actuator -->
<dependency>
  <groupId>org.springframework.boot</groupId>
  <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>

<!-- Micrometer Prometheus registry -->
<dependency>
  <groupId>io.micrometer</groupId>
  <artifactId>micrometer-registry-prometheus</artifactId>
</dependency>

<!-- Spring Kafka (already present in most Kafka apps) -->
<dependency>
  <groupId>org.springframework.kafka</groupId>
  <artifactId>spring-kafka</artifactId>
</dependency>
```

If you’re using Gradle:

```kotlin
implementation("org.springframework.boot:spring-boot-starter-actuator")
implementation("io.micrometer:micrometer-registry-prometheus")
implementation("org.springframework.kafka:spring-kafka")
```

These dependencies automatically enable Micrometer’s instrumentation and add the `/actuator/prometheus` endpoint.

## Configure Actuator and Prometheus Endpoint

Edit your `src/main/resources/application.yml`:

```yaml
server:
  port: 1234
  address: 0.0.0.0 # Ensure accessible from outside container

management:
  endpoints:
    web:
      exposure:
        include: prometheus,health,info
  endpoint:
    prometheus:
      enabled: true
  metrics:
    tags:
      application: banking-kafka-app
```

If you prefer `.properties`:

```properties
server.port=1234
server.address=0.0.0.0
management.endpoints.web.exposure.include=prometheus,health,info
management.endpoint.prometheus.enabled=true
management.metrics.tags.application=banking-kafka-app
```

Start your Spring Boot app and verify:

```bash
curl http://localhost:1234/actuator/prometheus
```

You should see metrics in Prometheus format (text-based output starting with `# HELP` and `# TYPE`).

## Allow Prometheus Access (Optional Security Configuration)

If your app uses Spring Security, expose the `/actuator/prometheus` endpoint by adding the following configuration:

```java
@Configuration
public class SecurityConfig {
  @Bean
  SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {
    http
      .authorizeHttpRequests(auth -> auth
        .requestMatchers("/actuator/prometheus", "/actuator/health", "/actuator/info").permitAll()
        .anyRequest().authenticated()
      )
      .csrf(csrf -> csrf.disable());
    return http.build();
  }
}
```

## Register Kafka Client Metrics (Producer and Consumer)

Micrometer does not automatically pick up Kafka client internals unless you explicitly bind them.

Create a component called `KafkaMetricsBinder.java`:

```java
import io.micrometer.core.instrument.MeterRegistry;
import io.micrometer.core.instrument.binder.kafka.KafkaClientMetrics;
import org.apache.kafka.clients.consumer.Consumer;
import org.apache.kafka.clients.producer.Producer;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;
import org.springframework.kafka.core.DefaultKafkaProducerFactory;
import org.springframework.stereotype.Component;
import jakarta.annotation.PostConstruct;

@Component
public class KafkaMetricsBinder {

    private final DefaultKafkaProducerFactory<?, ?> producerFactory;
    private final DefaultKafkaConsumerFactory<?, ?> consumerFactory;
    private final MeterRegistry meterRegistry;

    public KafkaMetricsBinder(DefaultKafkaProducerFactory<?, ?> producerFactory,
                              DefaultKafkaConsumerFactory<?, ?> consumerFactory,
                              MeterRegistry meterRegistry) {
        this.producerFactory = producerFactory;
        this.consumerFactory = consumerFactory;
        this.meterRegistry = meterRegistry;
    }

    @PostConstruct
    public void bindClientMetrics() {
        try (Producer<?, ?> producer = producerFactory.createProducer()) {
            new KafkaClientMetrics(producer).bindTo(meterRegistry);
        } catch (Exception ignored) {}

        try (Consumer<?, ?> consumer = consumerFactory.createConsumer()) {
            new KafkaClientMetrics(consumer).bindTo(meterRegistry);
        } catch (Exception ignored) {}
    }
}
```

This automatically registers all producer and consumer metrics with Micrometer.

## Configure Prometheus to Scrape the Application

Edit your `prometheus.yml` file (used by your Prometheus container):

```yaml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'banking-kafka-app'
    metrics_path: /actuator/prometheus
    static_configs:
      - targets: ['host.docker.internal:1234']
```

If `host.docker.internal` doesn’t resolve on Linux, add this to your `docker-compose.yml`:

```yaml
extra_hosts:
  - 'host.docker.internal:host-gateway'
```

Or replace it with your host IP, for example `192.168.1.100:1234`.

Restart Prometheus:

```bash
docker compose restart prometheus
```

Then check Prometheus UI → **Status > Targets**.
Your `banking-kafka-app` job should appear as **UP**.

## Verify Connectivity Inside Prometheus

You can verify that Prometheus can reach your Spring Boot app using:

```bash
docker exec -it prometheus wget -qO- http://host.docker.internal:1234/actuator/prometheus | head
```

You should see output similar to:

```
# HELP jvm_memory_used_bytes The amount of used memory
# TYPE jvm_memory_used_bytes gauge
jvm_memory_used_bytes{area="heap",...}
```

## Kafka Metrics Exposed by Micrometer

After `KafkaClientMetrics` is registered, Micrometer exposes Kafka client internals as Prometheus metrics.

### Producer Metrics

| Metric                                  | Description                                       |
| --------------------------------------- | ------------------------------------------------- |
| `kafka_producer_record_send_total`      | Total number of records sent (including retries). |
| `kafka_producer_record_error_total`     | Number of failed sends.                           |
| `kafka_producer_record_retry_total`     | Number of retries attempted.                      |
| `kafka_producer_request_latency_avg`    | Average request latency to broker.                |
| `kafka_producer_outgoing_byte_total`    | Total bytes sent.                                 |
| `kafka_producer_buffer_exhausted_total` | Number of times the producer buffer was full.     |
| `kafka_producer_batch_size_avg`         | Average batch size in bytes.                      |

### Consumer Metrics

| Metric                                  | Description                        |
| --------------------------------------- | ---------------------------------- |
| `kafka_consumer_records_consumed_total` | Total number of records consumed.  |
| `kafka_consumer_bytes_consumed_total`   | Total bytes consumed.              |
| `kafka_consumer_records_lag_max`        | Maximum lag across partitions.     |
| `kafka_consumer_commit_total`           | Total number of commits performed. |
| `kafka_consumer_fetch_latency_avg`      | Average latency of fetch requests. |

Each metric includes useful tags such as `client_id`, `topic`, `partition`, and `node_id`.

Example Prometheus output:

```
kafka_producer_record_send_total{client_id="producer-1",topic="payments"} 230.0
kafka_consumer_records_lag_max{client_id="consumer-1",topic="payments"} 2.0
```

## Visualizing in Grafana

Once Prometheus is scraping metrics, connect Grafana to your Prometheus data source.

Here are some useful PromQL queries:

| Purpose                  | Query                                         |
| ------------------------ | --------------------------------------------- |
| Producer send rate       | `rate(kafka_producer_record_send_total[1m])`  |
| Producer error rate      | `rate(kafka_producer_record_error_total[1m])` |
| Producer request latency | `kafka_producer_request_latency_avg`          |
| Consumer lag             | `kafka_consumer_records_lag_max`              |
| Consumer fetch latency   | `kafka_consumer_fetch_latency_avg`            |

You can visualize these as:

- Line charts for send rate and latency
- Gauges for consumer lag
- Tables for topic and partition-level details

## Common Issues

| Problem                            | Cause                                        | Solution                                        |
| ---------------------------------- | -------------------------------------------- | ----------------------------------------------- |
| Prometheus target shows UNKNOWN    | App not reachable or bound to localhost only | Add `server.address=0.0.0.0`                    |
| Prometheus cannot resolve host     | `host.docker.internal` missing in Linux      | Add `extra_hosts` entry in `docker-compose.yml` |
| `/actuator/prometheus` returns 404 | Missing Micrometer/Actuator dependency       | Add both dependencies to your project           |
| Kafka metrics missing              | Kafka clients not bound to Micrometer        | Register via `KafkaClientMetrics`               |

## Final Verification

1. Open Prometheus UI → [http://localhost:9090/targets](http://localhost:9090/targets)
   Ensure the `banking-kafka-app` target state is **UP**.
2. Query Prometheus:

   ```
   kafka_producer_record_send_total
   ```

   You should see producer metrics.

3. In Grafana, create a new panel with:

   ```
   rate(kafka_producer_record_send_total[1m])
   ```

   Observe the send rate graph as messages are produced.

## Summary

| Layer        | Technology            | Purpose                          |
| ------------ | --------------------- | -------------------------------- |
| Spring Boot  | Actuator + Micrometer | Collect metrics                  |
| Kafka Client | Producer / Consumer   | Generate internal client metrics |
| Prometheus   | Metrics collection    | Scrapes `/actuator/prometheus`   |
| Grafana      | Visualization         | Builds dashboards and alerts     |

This setup provides full visibility into your Kafka-based Spring Boot application, from JVM metrics to Kafka throughput and lag.

## Key Takeaways

- Micrometer bridges Spring Boot metrics to Prometheus.
- KafkaClientMetrics exposes Kafka producer and consumer internals.
- Prometheus periodically scrapes metrics for analysis.
- Grafana visualizes those metrics for operational insight.

This approach is ideal for both production monitoring and classroom demonstrations, illustrating how observability fits into modern, event-driven microservice architectures.
