# Building a Multi-Node Apache Kafka Cluster with Docker

Apache Kafka is a distributed streaming platform designed for **scalability**, **high throughput**, and **fault tolerance**.
While running a single Kafka broker is fine for development, production environments rely on **multi-node clusters** for reliability and parallelism.

## 1. Kafka Cluster Basics

A Kafka cluster typically consists of:

- **Multiple brokers** — Each broker is a Kafka server responsible for hosting partitions.
- **Zookeeper ensemble** — Coordinates broker metadata, leader election, and cluster membership (used in traditional Kafka setups).

Each broker has a unique `broker.id` and connects to the **same Zookeeper instance** to join the cluster automatically.

## 2. Cluster Architecture Overview

Example: A 3-broker Kafka cluster using a single Zookeeper.

```
+-------------------+
|     Zookeeper     |
|   (port: 2181)    |
+---------+----------+
          |
   -------------------------
   |           |           |
+--v--+     +--v--+     +--v--+
|Kafka|     |Kafka|     |Kafka|
| #1  |     | #2  |     | #3  |
|9092 |     |9093 |     |9094 |
+-----+     +-----+     +-----+
```

All brokers connect to the same Zookeeper, automatically forming one logical cluster.

## 3. Setting Up a Multi-Node Kafka Cluster (Using Confluent Images)

We’ll use **Docker Compose** to set up a 3-broker Kafka cluster.

Create a file named `docker-compose.yml`:

```yaml
version: '3.8'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.1
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - '2181:2181'

  kafka1:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka1
    ports:
      - '9092:9092'
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092
      KAFKA_LISTENERS: PLAINTEXT://:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_LOG_RETENTION_HOURS: 168
    depends_on:
      - zookeeper

  kafka2:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka2
    ports:
      - '9093:9093'
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9093
      KAFKA_LISTENERS: PLAINTEXT://:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
    depends_on:
      - zookeeper

  kafka3:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka3
    ports:
      - '9094:9094'
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:9094
      KAFKA_LISTENERS: PLAINTEXT://:9094
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
    depends_on:
      - zookeeper
```

Start the cluster:

```bash
docker compose up -d
```

You now have:

- Zookeeper → port `2181`
- Kafka brokers → ports `9092`, `9093`, and `9094`

## 4. Understanding Cluster Membership

When a new broker starts and connects to the same Zookeeper instance, it **automatically joins the existing cluster**.
Here’s what happens behind the scenes:

1. Broker connects to Zookeeper using `KAFKA_ZOOKEEPER_CONNECT`.
2. It registers itself under `/brokers/ids/<broker.id>`.
3. The controller broker detects it and updates the cluster metadata.
4. The broker becomes an active part of the cluster — no restart needed for others.

Verify the broker list:

```bash
docker exec -it kafka1 kafka-broker-api-versions --bootstrap-server kafka1:9092
```

Output example:

```
1 (id: 1 rack: null)
2 (id: 2 rack: null)
3 (id: 3 rack: null)
```

## 5. Verifying the Cluster

### Create a replicated topic

```bash
docker exec -it kafka1 kafka-topics --create \
  --topic transactions \
  --partitions 3 \
  --replication-factor 3 \
  --bootstrap-server kafka1:9092
```

### Describe the topic

```bash
docker exec -it kafka1 kafka-topics --describe \
  --topic transactions \
  --bootstrap-server kafka1:9092
```

Output:

```
Topic: transactions  PartitionCount: 3  ReplicationFactor: 3
Partition: 0  Leader: 1  Replicas: 1,2,3  Isr: 1,2,3
Partition: 1  Leader: 2  Replicas: 2,3,1  Isr: 2,3,1
Partition: 2  Leader: 3  Replicas: 3,1,2  Isr: 3,1,2
```

This confirms all three brokers are active and replicating data.

## 6. Adding a New Broker

To scale up:

1. Duplicate one of the Kafka services in your `docker-compose.yml`.
2. Change:

   - `container_name`
   - `ports`
   - `KAFKA_BROKER_ID`
   - `KAFKA_ADVERTISED_LISTENERS`

3. Run:

   ```bash
   docker compose up -d
   ```

Kafka automatically detects the new broker and adds it to the cluster.

Check:

```bash
docker exec -it kafka1 kafka-broker-api-versions --bootstrap-server kafka1:9092
```

## 7. Rebalancing Partitions

Adding brokers doesn’t automatically redistribute existing partitions.
Use the reassignment tool to balance load.

Generate a reassignment plan:

```bash
kafka-reassign-partitions.sh \
  --bootstrap-server kafka1:9092 \
  --generate \
  --topics-to-move-json-file topics.json \
  --broker-list "1,2,3,4"
```

Apply the reassignment:

```bash
kafka-reassign-partitions.sh \
  --bootstrap-server kafka1:9092 \
  --execute \
  --reassignment-json-file reassignment.json
```

This evenly distributes topic partitions across all available brokers.

## 8. Understanding `--bootstrap-server`

The `--bootstrap-server` parameter is used across all Kafka CLI tools.
It accepts a **comma-separated list** of broker addresses.

Example:

```bash
kafka-topics.sh --list \
  --bootstrap-server kafka1:9092,kafka2:9093,kafka3:9094
```

Kafka connects to one of these brokers to fetch the **cluster metadata**, after which it communicates directly with the responsible brokers.
This ensures high availability — if one broker is down, clients can still connect via others.

## 9. Useful Commands

List all topics:

```bash
kafka-topics.sh --list --bootstrap-server kafka1:9092
```

Consume messages:

```bash
kafka-console-consumer.sh \
  --topic transactions \
  --from-beginning \
  --bootstrap-server kafka1:9092,kafka2:9093
```

Describe consumer groups:

```bash
kafka-consumer-groups.sh \
  --describe \
  --group txn-group \
  --bootstrap-server kafka1:9092
```

## 10. Key Takeaways

| Concept                     | Description                                                              |
| --------------------------- | ------------------------------------------------------------------------ |
| **Cluster formation**       | Brokers join automatically when using the same Zookeeper                 |
| **Config path (Confluent)** | `/etc/kafka/server.properties`                                           |
| **Zookeeper role**          | Manages broker registry and controller election                          |
| **Rebalancing**             | Required for redistributing partitions to new brokers                    |
| **Bootstrap servers**       | Comma-separated broker list for client entry points                      |
| **Automatic discovery**     | Kafka fetches cluster metadata after initial connection                  |
| **Version pinning**         | Confluent images have explicit version tags (recommended for production) |

## 11. Conclusion

With this setup:

- You now have a **scalable, fault-tolerant Kafka cluster** running across multiple brokers.
- Brokers automatically join the cluster through **Zookeeper**.
- Clients connect reliably using **multiple bootstrap servers** for failover.
- You can easily scale by adding brokers and rebalancing topics.

This configuration provides the foundation for advanced use cases — from **event-driven microservices** to **stream analytics pipelines**.
