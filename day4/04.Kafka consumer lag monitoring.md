# Complete Guide: Kafka Consumer Lag Monitoring with Docker, Prometheus, and Grafana

## Introduction

Monitoring Kafka consumer lag is critical for maintaining healthy data pipelines. Consumer lag indicates how far behind your consumers are from the latest messages in a topic. High lag can signal performance issues, capacity problems, or consumer failures.

In this comprehensive tutorial, we'll build a complete Kafka monitoring stack using Docker Compose, including:

- Apache Kafka with Zookeeper
- Kafka UI for topic management
- Kafka Exporter for metrics collection
- Prometheus for time-series data storage
- Grafana for visualization

By the end, you'll have a production-ready monitoring system that tracks consumer lag in real-time.

## Prerequisites

- Docker and Docker Compose installed
- Basic understanding of Kafka concepts (topics, partitions, consumer groups)
- 8GB RAM recommended for running all services

## Architecture Overview

```
┌─────────────┐     ┌──────────────┐     ┌─────────────┐
│   Kafka     │────▶│Kafka Exporter│────▶│ Prometheus  │
│ (+ topics)  │     │  (metrics)   │     │(time-series)│
└─────────────┘     └──────────────┘     └─────────────┘
                                                  │
                                                  ▼
                                          ┌─────────────┐
                                          │   Grafana   │
                                          │(dashboards) │
                                          └─────────────┘
```

## Step 1: Project Setup

Create a new directory for your project:

```bash
mkdir kafka-monitoring
cd kafka-monitoring
```

Create the following directory structure:

```bash
mkdir -p grafana/provisioning/datasources
mkdir -p grafana/provisioning/dashboards
```

Your final structure should look like:

```
kafka-monitoring/
├── docker-compose.yml
├── prometheus.yml
└── grafana/
    └── provisioning/
        ├── datasources/
        │   └── prometheus.yml
        └── dashboards/
            ├── dashboard.yml
            └── kafka-lag.json
```

## Step 2: Docker Compose Configuration

Create `docker-compose.yml`:

```yaml
version: '3.8'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - '2181:2181'
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-logs:/var/lib/zookeeper/log
    networks:
      - kafka-network

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - '9092:9092'
      - '9101:9101'
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: kafka
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - kafka-network
    healthcheck:
      test:
        [
          'CMD-SHELL',
          'kafka-broker-api-versions --bootstrap-server localhost:9092',
        ]
      interval: 10s
      timeout: 10s
      retries: 5

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka
      - zookeeper
    ports:
      - '8080:8080'
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      KAFKA_CLUSTERS_0_METRICS_PORT: 9101
      DYNAMIC_CONFIG_ENABLED: 'true'
    networks:
      - kafka-network

  kafka-exporter:
    image: danielqsj/kafka-exporter:latest
    container_name: kafka-exporter
    depends_on:
      - kafka
    ports:
      - '9308:9308'
    command:
      - '--kafka.server=kafka:29092'
      - '--web.listen-address=:9308'
      - '--log.level=info'
    networks:
      - kafka-network
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - '9090:9090'
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    networks:
      - kafka-network
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    depends_on:
      - prometheus
    ports:
      - '3000:3000'
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
      GF_USERS_ALLOW_SIGN_UP: 'false'
      GF_INSTALL_PLUGINS: ''
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning/datasources:/etc/grafana/provisioning/datasources
      - ./grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards
    networks:
      - kafka-network
    restart: unless-stopped

volumes:
  zookeeper-data:
  zookeeper-logs:
  kafka-data:
  prometheus-data:
  grafana-data:

networks:
  kafka-network:
    driver: bridge
```

## Step 3: Prometheus Configuration

Create `prometheus.yml` in the root directory:

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'kafka-local'
    replica: '0'

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'kafka-exporter'
    static_configs:
      - targets: ['kafka-exporter:9308']
    relabel_configs:
      - source_labels: [__address__]
        target_label: instance
        replacement: 'kafka-cluster'

  - job_name: 'kafka-jmx'
    static_configs:
      - targets: ['kafka:9101']
    relabel_configs:
      - source_labels: [__address__]
        target_label: instance
        replacement: 'kafka-broker'
```

## Step 4: Grafana Auto-Provisioning

### Datasource Configuration

Create `grafana/provisioning/datasources/prometheus.yml`:

```yaml
apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: true
    jsonData:
      timeInterval: 15s
```

### Dashboard Provider Configuration

Create `grafana/provisioning/dashboards/dashboard.yml`:

```yaml
apiVersion: 1

providers:
  - name: 'Kafka Dashboards'
    orgId: 1
    folder: ''
    type: file
    disableDeletion: false
    updateIntervalSeconds: 10
    allowUiUpdates: true
    options:
      path: /etc/grafana/provisioning/dashboards
```

### Custom Dashboard

Create `grafana/provisioning/dashboards/kafka-lag.json` with a pre-configured dashboard (see the dashboard JSON in the artifacts section).

## Step 5: Start the Stack

Launch all services:

```bash
docker-compose up -d
```

Wait for all services to start (about 30-60 seconds):

```bash
docker-compose ps
```

All services should show "Up" status.

## Step 6: Verify the Setup

### Check Service Accessibility

- **Kafka UI**: http://localhost:8080
- **Prometheus**: http://localhost:9090
- **Grafana**: http://localhost:3000 (admin/admin)
- **Kafka Exporter Metrics**: http://localhost:9308/metrics

### Verify Prometheus Targets

1. Go to http://localhost:9090/targets
2. Ensure all targets show "UP" status:
   - prometheus
   - kafka-exporter
   - kafka-jmx

## Step 7: Understanding Consumer Lag

**Important Concept**: Kafka Exporter only reports metrics for consumer groups that actually exist. Unconsumed messages don't create lag metrics because there's no consumer to measure against.

To see lag metrics, you need:

1. A topic with messages
2. A consumer group that has registered with Kafka
3. The consumer group to have committed offsets

## Step 8: Create Demo Data

### Create a Topic

```bash
docker exec -it kafka kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic orders \
  --partitions 3 \
  --replication-factor 1
```

### Produce Messages

```bash
docker exec -it kafka bash -c '
for i in {1..100}; do
  echo "{\"order_id\": \"ORD-$i\", \"customer\": \"Customer-$i\", \"amount\": $((RANDOM % 1000))}" | \
  kafka-console-producer --bootstrap-server localhost:9092 --topic orders
done
'
```

**Result**: 100 messages in the `orders` topic, distributed across 3 partitions.

## Step 9: Create Consumer Lag

Now we'll create a slow consumer to generate visible lag:

```bash
docker exec -it kafka bash -c "
kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic orders \
  --group slow-consumer-group \
  --from-beginning | \
  while read line; do
    echo \$line
    sleep 2
  done
"
```

This consumer reads one message every 2 seconds, creating visible lag.

## Step 10: Monitor in Grafana

1. Open Grafana: http://localhost:3000
2. Navigate to "Kafka Consumer Lag Monitoring" dashboard
3. You should see:
   - **Consumer Group Lag by Partition**: Real-time lag per partition
   - **Total Lag Gauge**: Overall lag (decreasing slowly)
   - **Current Offset**: Consumer progress
   - **Latest Offset**: Topic's latest messages

## Step 11: Create Dynamic Lag Scenarios

### Scenario A: Lag Increase (Producer Faster than Consumer)

In a new terminal, produce messages continuously:

```bash
docker exec -it kafka bash -c "
for i in {101..200}; do
  echo '{\"order_id\": \"ORD-$i\", \"amount\": $((RANDOM % 1000))}' | \
  kafka-console-producer --bootstrap-server localhost:9092 --topic orders
  sleep 0.5
done
"
```

**Watch Grafana**: Lag will increase as producer (2 msg/sec) is faster than consumer (0.5 msg/sec).

### Scenario B: Multiple Consumer Groups

Start a fast consumer in a different group:

```bash
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic orders \
  --group fast-consumer-group \
  --from-beginning \
  --max-messages 200
```

**Watch Grafana**: You'll see two consumer groups with different lag profiles.

### Scenario C: Continuous Monitoring

Simulate a real production scenario:

**Terminal 1 - Continuous Producer**:

```bash
docker exec -it kafka bash -c "
counter=300
while true; do
  echo '{\"order_id\": \"ORD-\$counter\", \"timestamp\": \"'\$(date +%s)'\"}' | \
  kafka-console-producer --bootstrap-server localhost:9092 --topic orders
  counter=\$((counter + 1))
  sleep 1
done
"
```

**Terminal 2 - Variable Speed Consumer**:

```bash
docker exec -it kafka bash -c "
kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic orders \
  --group variable-consumer-group \
  --from-beginning | \
  while read line; do
    echo \$line
    sleep \$((RANDOM % 5))
  done
"
```

## Step 12: Monitoring Key Metrics

### Important Kafka Exporter Metrics

| Metric                                 | Description                     | Alert Threshold   |
| -------------------------------------- | ------------------------------- | ----------------- |
| `kafka_consumergroup_lag`              | Messages behind per partition   | > 1000 (warning)  |
| `kafka_consumergroup_lag_sum`          | Total lag across all partitions | > 5000 (critical) |
| `kafka_consumergroup_current_offset`   | Consumer's current position     | -                 |
| `kafka_topic_partition_current_offset` | Latest message offset           | -                 |
| `kafka_consumergroup_members`          | Active consumers in group       | = 0 (critical)    |

### Query Examples in Prometheus

**Total lag by consumer group**:

```promql
sum(kafka_consumergroup_lag) by (consumergroup)
```

**Lag rate of change**:

```promql
rate(kafka_consumergroup_lag[5m])
```

**Consumer groups with zero members**:

```promql
kafka_consumergroup_members == 0
```

**Partitions with highest lag**:

```promql
topk(5, kafka_consumergroup_lag)
```

## Step 13: Import Community Dashboards

For additional visualizations, import these Grafana dashboard IDs:

1. **Dashboard 7589** - Kafka Exporter Overview (recommended)
2. **Dashboard 12219** - Detailed Kafka Exporter
3. **Dashboard 10973** - Consumer Lag Focus

**How to import**:

- Grafana → Dashboards → Import
- Enter dashboard ID: `7589`
- Select "Prometheus" datasource
- Click Import

## Troubleshooting Guide

### Problem: No metrics in Grafana

**Solution 1**: Verify Kafka Exporter is collecting data:

```bash
curl http://localhost:9308/metrics | grep kafka_consumergroup_lag
```

**Solution 2**: Check Prometheus is scraping:

```bash
curl http://localhost:9090/api/v1/targets | jq '.data.activeTargets[] | {job: .labels.job, health: .health}'
```

**Solution 3**: Verify consumer groups exist:

```bash
docker exec -it kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --list
```

### Problem: Consumer group not showing

**Cause**: Consumer hasn't committed any offsets yet.

**Solution**: Ensure your consumer runs long enough to commit offsets (auto-commit interval is 1000ms by default).

### Problem: Imported dashboards show no data

**Cause**: Datasource UID mismatch or wrong Prometheus URL.

**Solution**:

1. Go to Dashboard Settings → JSON Model
2. Find all instances of `"uid": "..."`
3. Replace with your Prometheus datasource UID (usually "prometheus")

## Best Practices

### 1. Alert Configuration

Create Prometheus alerts for high lag:

```yaml
groups:
  - name: kafka_alerts
    rules:
      - alert: HighConsumerLag
        expr: kafka_consumergroup_lag > 1000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: 'High consumer lag detected'
          description: 'Consumer group {{ $labels.consumergroup }} has lag of {{ $value }}'
```

### 2. Retention Policy

Configure appropriate retention in `prometheus.yml`:

```yaml
global:
  scrape_interval: 15s
storage:
  tsdb:
    retention.time: 15d
    retention.size: 50GB
```

### 3. Consumer Group Naming

Use descriptive consumer group names:

- ✅ `orders-processing-service-prod`
- ❌ `consumer-1`

### 4. Partition Count

Balance partitions with consumer instances:

- Partitions = 3, Consumers = 3 ✅ (optimal)
- Partitions = 3, Consumers = 1 ⚠️ (limited throughput)
- Partitions = 3, Consumers = 10 ❌ (7 idle consumers)

## Advanced: Python Consumer Example

For programmatic monitoring:

```python
from kafka import KafkaConsumer
import time

consumer = KafkaConsumer(
    'orders',
    bootstrap_servers=['localhost:9092'],
    group_id='python-consumer-group',
    auto_offset_reset='earliest',
    enable_auto_commit=True,
    auto_commit_interval_ms=1000
)

for message in consumer:
    print(f"Consumed: {message.value.decode('utf-8')}")
    # Simulate processing time
    time.sleep(1)
```

## Cleanup

### Stop all services:

```bash
docker-compose down
```

### Remove volumes (deletes all data):

```bash
docker-compose down -v
```

### Delete specific topic:

```bash
docker exec -it kafka kafka-topics --delete \
  --bootstrap-server localhost:9092 \
  --topic orders
```

### Reset consumer group offsets:

```bash
docker exec -it kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --group slow-consumer-group \
  --reset-offsets --to-earliest \
  --topic orders \
  --execute
```

## Conclusion

You now have a complete Kafka monitoring stack that:

- ✅ Tracks consumer lag in real-time
- ✅ Visualizes metrics in Grafana
- ✅ Stores historical data in Prometheus
- ✅ Provides a UI for Kafka management
- ✅ Auto-provisions all configurations

This setup is production-ready with proper health checks, persistent volumes, and restart policies. You can extend it further with alerting, additional exporters, or integration with your existing monitoring infrastructure.
